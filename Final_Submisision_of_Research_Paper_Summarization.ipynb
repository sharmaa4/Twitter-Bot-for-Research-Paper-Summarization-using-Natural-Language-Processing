{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Submisision of Research Paper Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caeaadb09f824f72bde91e2a4486ac4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96be88265737406282cb89c8d2c67d5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b7445d577b443c1ad4241be62b7fa95",
              "IPY_MODEL_b31f1439fb4f427e815c2bcf04c814a2",
              "IPY_MODEL_608779c715ef4e04896c36b820c7e084"
            ]
          }
        },
        "96be88265737406282cb89c8d2c67d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b7445d577b443c1ad4241be62b7fa95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e8d345bbd1d41bc92ba3792745c5724",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b99f932e4f35409bafdb244b0486003b"
          }
        },
        "b31f1439fb4f427e815c2bcf04c814a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9972cbf227045239cf7a728cc3a34db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1009,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1009,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1cd8db5b7934eb886519efdf9e77b70"
          }
        },
        "608779c715ef4e04896c36b820c7e084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_848881f04a8449379056e87b8a2acd5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1009/1009 [17:06&lt;00:00,  1.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_034bacd0f4d54a0588f47d52d2f5bec3"
          }
        },
        "6e8d345bbd1d41bc92ba3792745c5724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b99f932e4f35409bafdb244b0486003b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9972cbf227045239cf7a728cc3a34db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1cd8db5b7934eb886519efdf9e77b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "848881f04a8449379056e87b8a2acd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "034bacd0f4d54a0588f47d52d2f5bec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmaa4/Twitter-Bot-for-Research-Paper-Summarization-using-Natural-Language-Processing/blob/main/Final_Submisision_of_Research_Paper_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVFb1IyfBCN2"
      },
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B72svn1EoNVg",
        "outputId": "5f96bf53-24ac-4987-af7f-07357fe1e021"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzR4OlOaK4Tg"
      },
      "source": [
        "!pip install -Uq fastbook\n",
        "!rm -rf /content/pdfminer.six\n",
        "!pip install pdfminer.six\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "import tweepy\n",
        "import webbrowser\n",
        "import time\n",
        "\n",
        "from lxml import etree\n",
        "from tqdm.auto import tqdm\n",
        "from fastai.text.all import *\n",
        "!git clone \"https://github.com/pdfminer/pdfminer.six\"\n",
        "!pip install pdfminer.six\n",
        "!pip install -Uq transformers\n",
        "!pip install -r '/content/drive/MyDrive/Colab Notebooks/requirements.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yi0oSEBYIV"
      },
      "source": [
        "## XML PARSING TO CONVERT INPUT DATA IN XML FORMAT TO STRINGS AND APPENDING THEM INTO A CSV FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkkkdyeMbam"
      },
      "source": [
        "root_path = '/content/drive/MyDrive/Colab Notebooks/scisummnet_release1.1__20190413/top1000_complete'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt1fDtV9MFTV"
      },
      "source": [
        "pathlist = os.listdir(root_path)\n",
        "# for folder in pathlist:\n",
        "#   print(os.listdir(root_path+'/'+folder+'/summary'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q-0lIyTMN07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "caeaadb09f824f72bde91e2a4486ac4d",
            "96be88265737406282cb89c8d2c67d5d",
            "9b7445d577b443c1ad4241be62b7fa95",
            "b31f1439fb4f427e815c2bcf04c814a2",
            "608779c715ef4e04896c36b820c7e084",
            "6e8d345bbd1d41bc92ba3792745c5724",
            "b99f932e4f35409bafdb244b0486003b",
            "f9972cbf227045239cf7a728cc3a34db",
            "e1cd8db5b7934eb886519efdf9e77b70",
            "848881f04a8449379056e87b8a2acd5a",
            "034bacd0f4d54a0588f47d52d2f5bec3"
          ]
        },
        "outputId": "9b3e3a06-da2c-401a-a343-c797b8697ce4"
      },
      "source": [
        "parser = etree.XMLParser(remove_blank_text=True)\n",
        "\n",
        "# papers\n",
        "pap_text = []\n",
        "summaries = []\n",
        "for folder in tqdm(pathlist):\n",
        "  tree = etree.parse(root_path+'/'+folder+'/Documents_xml/'+folder+'.xml', parser)\n",
        "  paper = []\n",
        "  for s in tree.iter():\n",
        "    if s.text is not None: paper.append(s.text)\n",
        "\n",
        "  with open(root_path+'/'+folder+'/summary/'+folder+'.gold.txt') as f:\n",
        "    lines = f.read()\n",
        "\n",
        "  pap_text.append(' '.join(paper))\n",
        "  summaries.append(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caeaadb09f824f72bde91e2a4486ac4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1009 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS6Dg7_qzvtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cace5eb3-0854-4fa7-d26c-6b3ca63599ee"
      },
      "source": [
        "scis_df = pd.DataFrame({'text':pap_text, 'summary':summaries})\n",
        "type(scis_df['text'].iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiVMYFjZ9Wvt"
      },
      "source": [
        "scis_df.to_csv('./scisumm.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO_fJEpUr-wQ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Manual train-test split\n",
        "np.random.seed(10) # seed added \n",
        "msk = np.random.rand(len(scis_df)) < 0.8\n",
        "msk\n",
        "train_df = scis_df[msk]\n",
        "test_df = scis_df[~msk]\n",
        "train_df.to_csv('/content/drive/MyDrive/Colab Notebooks/scisumm_train.csv')\n",
        "test_df.to_csv('/content/drive/MyDrive/Colab Notebooks/scisumm_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tzdTcpaPzxU"
      },
      "source": [
        "## FINE-TUNING BART WITH HUGGINGFACE SCRIPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7JPDvoJ8-S8"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "os.chdir(\"/content/transformers\")\n",
        "!pwd\n",
        "!pip install .\n",
        "\n",
        "!python '/content/drive/MyDrive/Colab Notebooks/run_summarization.py' \\\n",
        "    --model_name_or_path facebook/bart-large-cnn \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --train_file '/content/drive/MyDrive/Colab Notebooks/scisumm_train.csv' \\\n",
        "    --validation_file '/content/drive/MyDrive/Colab Notebooks/scisumm_test.csv' \\\n",
        "    --text_column text \\\n",
        "    --summary_column summary \\\n",
        "    --source_prefix \"summarize: \" \\\n",
        "    --output_dir \"/content/drive/MyDrive/Colab Notebooks/Summarization Output/\" \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size=1 \\\n",
        "    --per_device_eval_batch_size=1 \\\n",
        "    --predict_with_generate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOqnek8xB5d7"
      },
      "source": [
        "## MEASURING PERFORMANCE OF FINE-TUNED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvAg5pG3zCfU"
      },
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "PATH = \"/content/drive/MyDrive/Colab Notebooks/Summarization Output/\"\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained(PATH, local_files_only=True)\n",
        "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained(PATH, local_files_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28qOOJfcOS30"
      },
      "source": [
        "gen_summs = []\n",
        "for paper in tqdm(test_df.text.values[:203]):\n",
        "#for paper in tqdm(scis_df.text.values[:5]):\n",
        "\n",
        "  ARTICLE_TO_SUMMARIZE = paper\n",
        "  inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "  # Generate Summary\n",
        "  summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=500, early_stopping=True)\n",
        "  gen_summs.append([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n",
        "\n",
        "gen_df = pd.DataFrame({'generated_summary':gen_summs})\n",
        "gen_df.head()\n",
        "\n",
        "gen_df.generated_summary = gen_df.generated_summary.apply(lambda x: x[0])\n",
        "gen_df.head()\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge2', 'rouge3'])\n",
        "scores = []\n",
        "#mod: sharmaa4 for i in range(500):\n",
        "for i in range(203):\n",
        "  \n",
        "  scores.append(scorer.score(test_df.iloc[i].summary, gen_df.iloc[i].generated_summary))\n",
        "\n",
        "\n",
        "r2r = []\n",
        "r2f = []\n",
        "r3f = []\n",
        "#for i in range(250):\n",
        "for i in range(203):\n",
        "  r2r.append(scores[i]['rouge2'].recall)\n",
        "  r2f.append(scores[i]['rouge2'].fmeasure)\n",
        "  r3f.append(scores[i]['rouge3'].fmeasure)\n",
        "\n",
        "\n",
        "print('rouge2 - recall: '+ str(np.mean(r2r)))\n",
        "print('rouge2 - fmeasure: '+ str(np.mean(r2f)))\n",
        "print('rouge3 - fmeasure: '+ str(np.mean(r3f)))\n",
        "\n",
        "gen_df.to_csv('./nonpt_first500.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU6MRw9KCOCF"
      },
      "source": [
        "## FUNCTION TO GENERATE SUMMARY "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZAjF2U5OG_X"
      },
      "source": [
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1El7El2NjLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70531804-8ba6-4037-fac0-07c3d7dafd33"
      },
      "source": [
        "!git clone \"https://github.com/pdfminer/pdfminer.six\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pdfminer.six' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlOn7sCHwRqb"
      },
      "source": [
        "def gen_pdf_summary(url):\n",
        "\n",
        "  print(url)\n",
        "  !curl -o PDF {url}\n",
        "  !python /content/pdfminer.six/tools/pdf2txt.py PDF > ./PDF_text\n",
        "\n",
        "  with open(\"./PDF_text\",'r') as file:\n",
        "    text = file.read()\n",
        "  \n",
        "  inputs_1 = tokenizer(text[0:1024], max_length=1024, return_tensors='pt', truncation=True)\n",
        "  inputs_2 = tokenizer(text[1025:2048], max_length=1024, return_tensors='pt', truncation=True)\n",
        "  inputs_3 = tokenizer(text[2048:3072], max_length=1024, return_tensors='pt', truncation=True)\n",
        "  inputs_4 = tokenizer(text[3072:], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "  # Generate Summary\n",
        "  summary_ids_1 = model.generate(inputs_1['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "  summary_1 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_1]\n",
        "\n",
        "  summary_ids_2 = model.generate(inputs_2['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "  summary_2 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_2]\n",
        "\n",
        "  summary_ids_3 = model.generate(inputs_3['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "  summary_3 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_3]\n",
        "\n",
        "  summary_ids_4 = model.generate(inputs_4['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "  summary_4 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_4]\n",
        "  \n",
        "  return summary_1[0]+summary_2[0]+summary_3[0]+summary_4[0]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BnRJyOWU5zYM",
        "outputId": "8f3e0a25-a221-48f6-e64c-24ef4bde2b47"
      },
      "source": [
        "#gen_pdf_summary(\"https://arxiv.org/pdf/1909.01716v3.pdf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://arxiv.org/pdf/1909.01716v3.pdf\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  614k  100  614k    0     0   423k      0  0:00:01  0:00:01 --:--:--  423k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ScisummNet: A Large Annotated Corpus and Content-Impact Models\\nFor Scientiﬁc Paper Summarization with Citation Networks\\nRecent work in automatic summarization has achieved good results for news articles: single-Document Single-Document (SDS) summaries (Parveen, Ramsl, and Strube) and traditional citation-based summaries.\\nOur large annotated corpus and hybrid methods provide a new framework for science-oriented paper summarization research.\\nWe demonstrate the effectiveness of our corpus in producing large-scale manually-annotated summaries and the advantage of'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI26ysHlCQvT"
      },
      "source": [
        "## TWITTER BOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58beNTqmW3MG"
      },
      "source": [
        "# these are the necessary keys which we got from Twitter\n",
        "##consumer_key = \"Qm4Exmimzawm2WJ1wCIbBPDCK\"\n",
        "##consumer_secret = \"jDW4rd4sqwWM0t0nkEUXoRQnXYfpQjnJt4vqaxVhtfIaUb9PN9\"\n",
        "##access_token = \"1419176160127164417-hiXZsBeeONG7cUKDdkz28fvPlU5J6r\"\n",
        "##access_token_secret = \"kiyMn8EoCM3FbAF0jNHCBA59TtblJndRKmICwFv0ATIKW\"\n",
        "\n",
        "consumer_key = \"VXE0kwXAw2bUJ9dx5gnFNmLEG\"\n",
        "consumer_secret = \"LiebjWsYOcOXHWFsTTcfyxmPf13vWEc7xsgmrkVMJ4uXupkdI4\"\n",
        "access_token = \"1419176160127164417-C4b5obrAO2EpwFnWBKC6XtQ6SJWwrO\"\n",
        "access_token_secret = \"6WvekVxHlnQ6GWKSq1APhVPq3GpQg9gAd0NDBpzfP5k5V\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJ-4ActW4Mq"
      },
      "source": [
        "# as of now we need to get tweets from this user, so we pick his user ID\n",
        "userID = \"ak92501\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc7n1fLYW7e0"
      },
      "source": [
        "# authorizing our twitter credentials\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq5RtkFoW_nG"
      },
      "source": [
        "# user_timeline extends tweets from particular user\n",
        "tweets = api.user_timeline(screen_name=userID, \n",
        "                           # 200 is the maximum allowed count\n",
        "                           count=200,\n",
        "                           include_rts = True,\n",
        "                           tweet_mode = 'extended'\n",
        "                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "XYqZa2_guJLF",
        "outputId": "e43edd75-ac83-4701-c51e-c29f81939f5a"
      },
      "source": [
        "# these are the recent 10 tweets from AK\n",
        "def extract_pdf_link_from_tweet():\n",
        "\n",
        "  for info in tweets[14:15]:\n",
        "    link = \"\"\n",
        "    print(\"ID: {}\".format(info.id))\n",
        "    print(info.created_at)\n",
        "    print(info.full_text)\n",
        "    print(\"\\n\")\n",
        "    pdf_link = re.search(\"pdf:.*\",info.full_text)\n",
        "     \n",
        "\n",
        "    if(pdf_link != None):\n",
        "      pdf_link_list = pdf_link.string.split(\"\\n\")\n",
        "      for i in pdf_link_list:\n",
        "         if(\"pdf: \" in i) :\n",
        "            print(\"PDF Link: \",i)\n",
        "            link_list = i.split(\" \")\n",
        "            link = link_list[1]\n",
        "          \n",
        "\n",
        "  return link      \n",
        "\n",
        "\n",
        "#extract_pdf_link_from_tweet()      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID: 1420856997583413262\n",
            "2021-07-29 21:21:21\n",
            "RT @abidlabs: By now, you've probably heard about Hugging Face Spaces, a *free* way to host @Gradio demos, like this cool depth perception…\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dx8PP9FmgPz"
      },
      "source": [
        "import requests\n",
        "def unshorten_url(url=\"\"):\n",
        "  \n",
        "  session = requests.Session()  # so connections are recycled\n",
        "  resp = session.head(url, allow_redirects=True)\n",
        "  \n",
        "  return resp.url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-8Jmv17XGVg"
      },
      "source": [
        "# Posting on Twitter\n",
        "def tweet_summary(tweet=\"\",user_id=\"\"):\n",
        "  \n",
        "  tweet_list = tweet.split('\\n')\n",
        "  tweet_list\n",
        "  count = 0\n",
        "  my_id=\"@Summarizer19 \"\n",
        "  for i in tweet_list[:-1] :\n",
        "      count = count+1\n",
        "      if(count == 1):\n",
        "        head = \"Requested By \"+\"@\"+user_id+\" \"\n",
        "        print(i)\n",
        "        try:\n",
        "          original_tweet = api.update_status(status=head+i)\n",
        "        except tweepy.TweepError:\n",
        "          print(\"Could not tweet due to some issue\")\n",
        "          break\n",
        "      else:\n",
        "        print(my_id+i)\n",
        "        if(count == 2):\n",
        "          try: \n",
        "            reply_tweet = api.update_status(status=my_id+i, \n",
        "                                 in_reply_to_status_id=original_tweet.id, \n",
        "                                 auto_populate_reply_metadata=False)\n",
        "          except tweepy.TweepError:\n",
        "            print(\"Could not tweet due to some issue\")\n",
        "            break\n",
        "        else:\n",
        "          try:\n",
        "            reply_tweet = api.update_status(status=my_id+i, \n",
        "                                 in_reply_to_status_id=reply_tweet.id, \n",
        "                                 auto_populate_reply_metadata=False)\n",
        "          except tweepy.TweepError:\n",
        "            print(\"Could not tweet due to some issue\")\n",
        "            break\n",
        "        \n",
        "  count = 0      \n",
        "\n",
        "#tweet_summary(gen_pdf_summary(unshorten_url(extract_pdf_link_from_tweet())),user_id=\"ak92501\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0RPcFEsTzAg",
        "outputId": "8de6be0a-67b9-450b-cf89-5a14aa979322"
      },
      "source": [
        "api.list_direct_messages(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DirectMessage(_api=<tweepy.api.API object at 0x7f7afc6b3190>, _json={'type': 'message_create', 'id': '1421023655350259719', 'created_timestamp': '1627633415435', 'message_create': {'target': {'recipient_id': '1419176160127164417'}, 'sender_id': '1321213011911004161', 'message_data': {'text': 'Hi', 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}}}}, type='message_create', id='1421023655350259719', created_timestamp='1627633415435', message_create={'target': {'recipient_id': '1419176160127164417'}, 'sender_id': '1321213011911004161', 'message_data': {'text': 'Hi', 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}}})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swSNt51P9l_v"
      },
      "source": [
        "def lookup_for_dms():\n",
        "  global latest_dm_timestamp\n",
        "  \n",
        "  \n",
        "\n",
        "  messages = api.list_direct_messages(1)\n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "  output_link = \"\"\n",
        "  output_user_id = \"\"\n",
        "\n",
        "  for message in messages:\n",
        "     if(int(message.created_timestamp) <= int(latest_dm_timestamp)):\n",
        "       break\n",
        "\n",
        "     if(len(message.message_create['message_data']['entities']['urls']) != 0):\n",
        "       print(message.message_create['message_data']['entities']['urls'])\n",
        "       #link = str(message.message_create['message_data']['entities']['urls'])\n",
        "       link = str(message.message_create['message_data']['entities']['urls'])\n",
        "       list_link= link.split(\",\")\n",
        "       #print(list_link[1])\n",
        "       list_expanded_link = list_link[1].split(\": \")\n",
        "       if(\"arxiv.org\" in list_expanded_link[1]):\n",
        "         expanded_arxiv_link = list_expanded_link[1]\n",
        "         print(expanded_arxiv_link)\n",
        "         output_link = expanded_arxiv_link\n",
        "       else:\n",
        "         print(\"Not an arxiv link\\n\")\n",
        "\n",
        "     else:\n",
        "       print(\"DM does not have a link\")\n",
        "\n",
        "\n",
        "     if(len(message.message_create['message_data']['entities']['user_mentions']) != 0):\n",
        "    \n",
        "       user_mentions = str(message.message_create['message_data']['entities']['user_mentions'])\n",
        "\n",
        "       user_mentions_list = user_mentions.split(\",\")\n",
        "       screen_name = user_mentions_list[0].split(\": \")\n",
        "       user_name = screen_name[1]\n",
        "    \n",
        "       print(\"User_id: \",user_name)\n",
        "\n",
        "       output_user_id = user_name\n",
        "  \n",
        "     else:\n",
        "       print(\"No username provided\")\n",
        "\n",
        "  if(int(message.created_timestamp) > int(latest_dm_timestamp)):\n",
        "    output = []  \n",
        "    output.append(output_link) \n",
        "    output.append(output_user_id)\n",
        "  \n",
        "  else:\n",
        "    output = []  \n",
        "    output.append(None) \n",
        "    output.append(None)\n",
        "\n",
        "  latest_dm_timestamp = message.created_timestamp\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  print(message)\n",
        "\n",
        "  \n",
        "\n",
        "  return output\n",
        "\n",
        "#latest_dm_timestamp = 0\n",
        "#requests = lookup_for_dms() \n",
        "#if(requests[0] != None):\n",
        "#  print(\"LINK:\",requests[0])\n",
        "#  print(\"LAST DM TIMESTAMP\",latest_dm_timestamp)\n",
        "#else:\n",
        "#  print(\"No Link\")\n",
        "#  print(\"LAST DM TIMESTAMP\",latest_dm_timestamp)\n",
        "#tweet_summary(gen_pdf_summary(requests[0]),user_id=requests[1][1:-1])  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0xBgkofqMO0"
      },
      "source": [
        "import time\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger()\n",
        "\n",
        "#latest_dm_timestamp = 0\n",
        "\n",
        "while True:\n",
        "  print(\"Hello\\n\")\n",
        "  requests = lookup_for_dms()\n",
        "  if(requests[0] != None ):\n",
        "    if(requests[0] != \"\"):\n",
        "      print(\"LINK:\",requests[0])\n",
        "      tweet_summary(gen_pdf_summary(requests[0]),user_id=requests[1][1:-1])\n",
        "  else:\n",
        "    print(\"No Link in the latest DM or Summary has been already posted for the current DM\")\n",
        "    \n",
        "\n",
        "  \n",
        "  logger.info(\"Waiting...\")\n",
        "  time.sleep(60)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}